<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
    <title>LLaVA-OneVision: Visual Task Transfer Made Easy</title>
    <meta name="generator" content="Jekyll v3.9.4" />
    <meta property="og:title" content="LLaVA-OneVision: Visual Task Transfer Made Easy" />
    <meta name="author" content="Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li" />
    <meta property="og:locale" content="en_US" />
    <meta name="description" content="LLaVA-OneVision: Visual Task Transfer Made Easy" />
    <meta property="og:description" content="LLaVA-OneVision: Visual Task Transfer Made Easy" />
    <link rel="canonical" href="https://llava-vl.github.io/blog/2024-08-05-llava-onevision/" />
    <meta property="og:url" content="https://llava-vl.github.io/blog/2024-08-05-llava-onevision/" />
    <meta property="og:site_name" content="LLaVA-NeXT" />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2024-08-05T12:33:38-06:00" />
    <meta name="twitter:card" content="summary" />
    <meta property="twitter:title" content="LLaVA-OneVision: Visual Task Transfer Made Easy" />
    <script type="application/ld+json">
        {
            "@context": "https://schema.org",
            "@type": "BlogPosting",
            "author": {
                "@type": "Person",
                "name": "Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li"
            },
            "dateModified": "2024-05-10T12:33:38-06:00",
            "datePublished": "2024-05-10T12:33:38-06:00",
            "description": "LLaVA team presents LLaVA-OneVision, Visual Task Transfer Made Easy",
            "headline": "LLaVA-OneVision: Visual Task Transfer Made Easy ",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://llava-vl.github.io/blog/2024-08-05-llava-onevision/"
            },
            "url": "https://llava-vl.github.io/blog/2024-08-05-llava-onevision/"
        }
    </script>
    <!-- End Jekyll SEO tag -->
    <link rel="stylesheet" href="/blog/assets/main.css">
    <link type="application/atom+xml" rel="alternate" href="https://llava-vl.github.io/blog/feed.xml" title="LLaVA" />
    <link rel="icon" type="image/x-icon" href="/blog/assets/images/logos/favicon.ico">
</head>

<body>
    <header class="site-header" role="banner">

        <div class="wrapper"><a class="site-title" rel="author" href="/blog/">LLaVA</a>
            <nav class="site-nav">
                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

                <div class="trigger"></div>
            </nav>
        </div>
    </header>
    <main class="page-content" aria-label="Content">
        <div class="wrapper">
            <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

                <header class="post-header">
                    <h1 class="post-title p-name" itemprop="name headline">LLaVA-OneVision: Visual Task Transfer Made Easy </h1>
                    <p class="post-meta">
                        <time class="dt-published" datetime="2024-05-10T123:33:38-06:00" itemprop="datePublished">Aug 05, 2024
      </time>â€¢ <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li</span></span>
                    </p>
                </header>

                <div class="post-content e-content" itemprop="articleBody">
                    <!-- for mathjax support -->

                    <script type="text/x-mathjax-config">
                        MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, TeX: { equationNumbers: { autoNumber: "AMS" } } });
                    </script>

                    <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

                    <p>
						We present LLaVA-OneVision, a family of open large multimodal models (LMMs) developed by consolidating our insights into data, models, and visual representations in the <a href="https://llava-vl.github.io/blog/">LLaVA-NeXT blog series</a>. Our experimental results demonstrate show that LLaVA-OneVision is the first single model that can simultaneously push the performance boundaries of open LMMs in three important computer vision scenarios: single-image, multi-image and video scenarios. Importantly, the design of LLaVA-OneVision allow strong transfer learning across different modalities/scenarios, yielding new emerging capabilities. In particular, strong video understanding and cross-scenario capabilities are demosntrated through task transfer from images to videos.
                    </p>

                    <h3 id="open-source-release">Open-Source Release</h3>
                    <p>We open-source the LLaVA-OneVision to facilitate future development of LMM in the community. Code, data, model will be made publicly available.</p>

                    <ul>
                        <li><a href="https://huggingface.co/lmms-lab">Model Checkpoints</a></li>
                        <li><a href="https://github.com/LLaVA-VL/LLaVA-NeXT">Inference Code</a></li>
                        <li><a href="https://llava-next.lmms-lab.com/">Live Demo</a></li>
                        <!-- <li><a href="https://huggingface.co/lmms-lab">LLaVA-Bench (Wilder): To be public later.</a></li> -->
                    </ul>


                    <h2 id="team">Team</h2>

                    <ul>
                        <li><a href="https://brianboli.com/">Bo Li</a>: Nanyang Technological University<img width="16" src="/blog/assets/images/logos/ntu.png" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://zhangyuanhan-ai.github.io/">Yuanhan Zhang</a>: Nanyang Technological University<img width="16" src="/blog/assets/images/logos/ntu.png" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
                        <li><a href="https://www.linkedin.com/in/dongguoset">Dong Guo</a>: ByteDance/Tiktok<img width="16" src="/blog/assets/images/logos/tiktok.png" />
						<li><a href="https://zrrskywalker.github.io/">Renrui Zhang</a>: The Chinese University of Hong Kong<img width="16" src="/blog/assets/images/logos/cuhk.jpg" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://fengli-ust.github.io/">Feng Li</a>: Hong Kong University of Science and Technology<img width="16" src="/blog/assets/images/logos/hkust.jpg" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://haozhang534.github.io/">Hao Zhang</a>: Hong Kong University of Science and Technology<img width="16" src="/blog/assets/images/logos/hkust.jpg" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://www.linkedin.com/in/kaichen-zhang-014b17219/?originalSubdomain=sg">Kaichen Zhang</a>: Nanyang Technological University<img width="16" src="/blog/assets/images/logos/ntu.png" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://yanwei-li.com/">Yanwei Li</a>: The Chinese University of Hong Kong<img width="16" src="/blog/assets/images/logos/cuhk.jpg" /> (<em>Work collaborated with ByteDance/TikTok</em>)</li>
						<li><a href="https://liuziwei7.github.io/">Ziwei Liu</a>: Nanyang Technological University<img width="16" src="/blog/assets/images/logos/ntu.png" />
                        <li><a href="https://chunyuan.li/">Chunyuan Li</a>: Bytedance/Tiktok<img width="16" src="/blog/assets/images/logos/tiktok.png" />
                    </ul>

                    <h2 id="acknowledgement">Related Blogs</h2>

                    <ul>
                        <li><a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">LLaVA-NeXT: Improved reasoning, OCR, and world knowledge</a></li>

                        <li><a href="https://llava-vl.github.io/blog/2024-04-30-llava-next-video/">LLaVA-NeXT: A Strong Zero-shot Video Understanding Model</a></li>
                        <li><a href="https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/">LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild</a></li>
                        <li><a href="https://llava-vl.github.io/blog/2024-05-25-llava-next-ablations/">LLaVA-NeXT: What Else Influences Visual Instruction Tuning Beyond Data?</a></li>
                        <li><a href="https://llava-vl.github.io/blog/2024-06-16-llava-next-interleave/">LLaVA-NeXT: Tackling Multi-image, Video, and 3D in Large Multimodal Models</a></li>
                        <li><a href="https://lmms-lab.github.io/lmms-eval-blog/lmms-eval-0.1/">Accelerating the Development of Large Multimodal Models with LMMs-Eval</a></li>
                    </ul>

                    <h2 id="citation">Citation</h2>

                    <div class="language-bibtex highlighter-rouge">
                        <div class="highlight"><pre class="highlight"><code>

<span class="nc">@misc</span><span class="p">{</span><span class="nl">li2024llava-onevision</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{LLaVA-OneVision: Visual Task Transfer Made Easy}</span><span class="p">,</span>
    <span class="na">url</span><span class="p">=</span><span class="s">{https://llava-vl.github.io/blog/2024-08-05-llava-onevision/}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan}</span><span class="p">,</span>
    <span class="na">month</span><span class="p">=</span><span class="s">{Aug}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span>
</code></pre></div>
                    </div>

                    </div>
                    <a class="u-url" href="/blog/2024-08-05-llava-onevision/" hidden></a>
            </article>

            </div>
    </main>
    <footer class="site-footer h-card">
        <data class="u-url" href="/blog/"></data>

        <div class="wrapper">

            <h2 class="footer-heading">LLaVA-NeXT</h2>

            <div class="footer-col-wrapper">
                <div class="footer-col footer-col-1">
                    <ul class="contact-list">
                        <li class="p-name">LLaVA-NeXT</li>
                    </ul>
                </div>

                <div class="footer-col footer-col-2">
                    <ul class="social-media-list"></ul>
                </div>

                <div class="footer-col footer-col-3">
                    <p></p>
                </div>
            </div>

        </div>

    </footer>
</body>

</html>